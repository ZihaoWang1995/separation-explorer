{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotherm processing\n",
    "\n",
    "This notebook will process isotherms selected previously to generate KPI values for each one. To run this notebook the root directory must be the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import pygaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: 'pressure_unit' was not specified, assumed as 'bar'\nWARNING: 'pressure_mode' was not specified, assumed as 'absolute'\nWARNING: 'adsorbent_unit' was not specified, assumed as 'g'\nWARNING: 'adsorbent_basis' was not specified, assumed as 'mass'\nWARNING: 'loading_unit' was not specified, assumed as 'mmol'\nWARNING: 'loading_basis' was not specified, assumed as 'molar'\nSelected20913isotherms\nLoaded 20913 isotherms.\n"
    }
   ],
   "source": [
    "# Database location\n",
    "db_path = pathlib.Path.cwd() / \"data\" / \"iso.db\"\n",
    "\n",
    "# Get all isotherms\n",
    "isotherms = pygaps.db_get_isotherms(db_path, {})\n",
    "\n",
    "print(f'Loaded {len(isotherms)} isotherms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute uptake values on pre-determined pressures. Do not extrapolate above maximum range. If any value below minimum range, use Henry constant to compute loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0%|          | 0/20913 [00:00<?, ?it/s]C:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n  app.launch_new_instance()\n100%|██████████| 20913/20913 [01:53<00:00, 183.56it/s]\n"
    }
   ],
   "source": [
    "no_loading_possible = []\n",
    "model_possible = []\n",
    "\n",
    "for iso in tqdm(isotherms):\n",
    "\n",
    "    iso.uptake = {}\n",
    "\n",
    "    prange = np.arange(0.5, 20.5, 0.5)\n",
    "    minp = min(iso.pressure(branch='ads'))\n",
    "    maxp = max(iso.pressure(branch='ads'))\n",
    "    model = [a for a in prange if a < minp]\n",
    "    direct = [a for a in prange if minp < a < maxp]\n",
    "\n",
    "    try:\n",
    "        for p in direct:\n",
    "            iso.uptake[p] = np.asscalar(iso.loading_at(p))\n",
    "    except Exception:\n",
    "        no_loading_possible.append(iso)\n",
    "        continue\n",
    "    # Take the data between 0 and x from the henry model\n",
    "    if model:\n",
    "        for p in model:\n",
    "            iso.uptake[p] = iso.henry_k * p\n",
    "        model_possible.append(iso)\n",
    "\n",
    "    iso.uptake[0] = 0.  # we automatically include 0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The calculated KPI are saved in a separate table in a HDF5 database. This will allow very fast retrieval when the dashboard is operated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 20913/20913 [00:00<00:00, 40234.00it/s]\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->axis0] [items->None]\n\n  f(store)\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->block0_items] [items->None]\n\n  f(store)\n"
    }
   ],
   "source": [
    "simple_dict = {}\n",
    "\n",
    "for iso in tqdm(isotherms):\n",
    "\n",
    "    addition = {\n",
    "        'mat' : iso.material,\n",
    "        'ads' : str(iso.adsorbate),\n",
    "        't' : iso.temperature,\n",
    "        'type' : iso.iso_type,\n",
    "        'kH' : np.log(iso.henry_k),\n",
    "    }\n",
    "    for p in np.arange(0.5, 20.5, 0.5):\n",
    "\n",
    "        addition[p] = iso.uptake.get(p, None)\n",
    "\n",
    "    simple_dict[iso.filename] = addition\n",
    "\n",
    "df = pd.DataFrame.from_dict(simple_dict, orient='index')\n",
    "df.to_hdf(pathlib.Path.cwd() / 'data' / 'kpi.h5', 'table', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For real isotherms to be displayed in the dashboard, some values are saved in an on-disk database. Here we use the python Shelve module for quick key-value pair storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 20913/20913 [03:25<00:00, 101.87it/s]\n"
    }
   ],
   "source": [
    "import shelve\n",
    "\n",
    "iso_packed = \"./data/iso-packed\"\n",
    "\n",
    "with shelve.open(iso_packed) as packed_dict:\n",
    "    for iso in tqdm(isotherms):\n",
    "        packed_dict[iso.filename] = {\n",
    "            'adsorbate': str(iso.adsorbate),\n",
    "            'material': iso.material,\n",
    "            'temp': iso.temperature,\n",
    "            'x': iso.pressure(),\n",
    "            'y': iso.loading(),\n",
    "            'doi': iso.DOI,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(pathlib.Path.cwd() / 'data' / 'kpi.h5', 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->axis0] [items->None]\n\n  f(store)\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->block0_items] [items->None]\n\n  f(store)\n"
    }
   ],
   "source": [
    "df.sample(n=500, random_state=1).to_hdf(pathlib.Path.cwd() / 'data' / 'kpi-smol.h5', 'table', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4413"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['mat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "554\n694\n"
    }
   ],
   "source": [
    "# select on experiment\n",
    "select = None\n",
    "if select:\n",
    "    dft = df[df['type']==select]\n",
    "else:\n",
    "    dft = df\n",
    "\n",
    "# select on temperature\n",
    "t_val = 303\n",
    "t_mar = 10\n",
    "dft = dft[dft['t'].between(t_val - t_mar, t_val + t_mar)]\n",
    "\n",
    "# create two clean dataframes with only material\n",
    "g1 = dft[dft['ads'] == 'nitrogen'].reset_index().drop(['index', 'type', 't', 'ads'], axis=1)\n",
    "g2 = dft[dft['ads'] == 'methane'].reset_index().drop(['index', 'type', 't', 'ads'], axis=1)\n",
    "\n",
    "# select only common materials\n",
    "common = list(set(g1['mat'].unique()).intersection(g2['mat'].unique()))\n",
    "g1 = g1[g1['mat'].isin(common)]\n",
    "g2 = g2[g2['mat'].isin(common)]\n",
    "\n",
    "print(len(g1))\n",
    "print(len(g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "def stats(series):\n",
    "\n",
    "    no_nan = series.dropna()\n",
    "    size = len(no_nan)\n",
    "\n",
    "    if size == 0:\n",
    "        med, std = np.nan, 0\n",
    "    elif size == 1:\n",
    "        med, std = float(no_nan), 0\n",
    "    elif 1 < size <= 4:\n",
    "        med, std = np.median(no_nan), np.std(no_nan)\n",
    "    elif 4 < size:\n",
    "        # Computing IQR\n",
    "        Q3, Q1 = np.nanpercentile(sorted(no_nan), [75, 25], interpolation='linear')\n",
    "        IQR = Q3 - Q1\n",
    "        o_rem = no_nan[(Q1 - 1.5 * IQR < no_nan) | (no_nan > Q3 + 1.5 * IQR)]\n",
    "        med, std = np.median(o_rem), np.std(o_rem)\n",
    "\n",
    "    return size, med, std\n",
    "\n",
    "\n",
    "def func(series):\n",
    "    return pd.Series(stats(series), index=([\"size\", \"med\", \"err\"]), \n",
    "                     name=series.name)\n",
    "\n",
    "@contextmanager\n",
    "def _group_selection_context(groupby):\n",
    "    \"\"\"\n",
    "    Set / reset the _group_selection_context.\n",
    "    \"\"\"\n",
    "    groupby._set_group_selection()\n",
    "    yield groupby\n",
    "    groupby._reset_group_selection()\n",
    "\n",
    "temp = None\n",
    "def desc(data):\n",
    "    return pd.concat([func(s) for _, s in data.items()], axis=1, sort=False)\n",
    "\n",
    "def proc(data):\n",
    "    with _group_selection_context(data):\n",
    "        return data.apply(\n",
    "            lambda x: pd.concat(\n",
    "                [func(s) for _, s in x.items()], \n",
    "                axis=1, sort=False)\n",
    "            ).unstack()\n",
    "\n",
    "# %timeit proc(test.groupby('mat'))\n",
    "# %timeit test.groupby('mat').agg(process)\n",
    "# proc(test.groupby('mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "59.0"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = proc(test.groupby('mat'))\n",
    "final.loc['CuBTC', ('kH_x', 'size')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'mat': ['co2', 'co2', 'co2', 'n2', 'co2', 'n2', 'ch4', 'n2', 'co2', 'co2'],\n",
    "                   'kH': np.random.randn(10),\n",
    "                   'L': np.random.randn(10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000273353E5288>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[dft['ads'] == 'nitrogen'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "--- 28.004876613616943 seconds ---\n"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# final = pd.merge(\n",
    "#     dft[dft['ads'] == 'nitrogen'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False).agg(stats),\n",
    "#     dft[dft['ads'] == 'methane'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False).agg(stats),\n",
    "#     on=('mat'), suffixes=('_x', '_y'))\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "final = pd.merge(\n",
    "    proc(dft[dft['ads'] == 'nitrogen'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "    proc(dft[dft['ads'] == 'methane'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "    on=('mat'), suffixes=('_x', '_y'))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = None\n",
    "if select:\n",
    "    sv = [select]\n",
    "else:\n",
    "    sv = ['unk', 'exp', 'sim']\n",
    "t_abs = 303\n",
    "t_tol = 10\n",
    "g1 = 'nitrogen'\n",
    "g2 = 'methane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method2():\n",
    "    def single_g(gas):\n",
    "        if select:\n",
    "            return df[\n",
    "                (df['type'] == select) &\n",
    "                (df['t'].between(t_abs - t_tol, t_abs + t_tol)) &\n",
    "                (df['ads'] == gas)\n",
    "            ].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)\n",
    "        else:\n",
    "            return df[\n",
    "                (df['t'].between(t_abs - t_tol, t_abs + t_tol)) &\n",
    "                (df['ads'] == gas)\n",
    "            ].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)\n",
    "\n",
    "    return single_g(g1), single_g(g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method3():\n",
    "    if select:\n",
    "        dft = df[\n",
    "            (df['type'] == select) &\n",
    "            (df['t'].between(t_abs - t_tol, t_abs + t_tol))\n",
    "        ]\n",
    "    else:\n",
    "        dft = df[df['t'].between(t_abs - t_tol, t_abs + t_tol)]\n",
    "        \n",
    "    common = list(set(dft['mat'].unique()).intersection(dft['mat'].unique()))\n",
    "\n",
    "    return (\n",
    "        dft[(dft['ads'] == g1) & (dft['mat'].isin(common))].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False),\n",
    "        dft[(dft['ads'] == g2) & (dft['mat'].isin(common))].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "14.4 s ± 1.57 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "def method4():\n",
    "    if select:\n",
    "        dft = df[\n",
    "            (df['type'] == select) &\n",
    "            (df['t'].between(t_abs - t_tol, t_abs + t_tol))\n",
    "        ]\n",
    "    else:\n",
    "        dft = df[df['t'].between(t_abs - t_tol, t_abs + t_tol)]\n",
    "    \n",
    "    g1_filt = dft[dft['ads'] == g1]\n",
    "    g2_filt = dft[dft['ads'] == g2]\n",
    "    common = list(set(g1_filt['mat'].unique()).intersection(g2_filt['mat'].unique()))\n",
    "\n",
    "    return pd.merge(\n",
    "        proc(g1_filt[g1_filt['mat'].isin(common)].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "        proc(g2_filt[g2_filt['mat'].isin(common)].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "        on=('mat'), suffixes=('_x', '_y'))\n",
    "%timeit method4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10 ms ± 1.02 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n10 ms ± 467 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n9.97 ms ± 244 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
    }
   ],
   "source": [
    "# grouped1 = dft[dft['ads'] == 'nitrogen'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)\n",
    "# grouped2 = dft[dft['ads'] == 'methane'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)\n",
    "\n",
    "# common = list(set(grouped1.groups.keys()).intersection(grouped2.groups.keys()))\n",
    "\n",
    "\n",
    "# print(len(grouped1.groups.keys()))\n",
    "# print(len(grouped2.groups.keys()))\n",
    "\n",
    "# print(len(common))\n",
    "# len(grouped1.filter(lambda x: x.name in common).groups.keys())\n",
    "%timeit method1()\n",
    "%timeit method2()\n",
    "%timeit method3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = 'propane'\n",
    "g2 = 'carbon dioxide'\n",
    "ret = method4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.013044685266911256"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.loc['MIL-53(Cr)'].loc[('1.0_x', 'med')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old methods\n",
    "Construct dictionary with results on a material basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = {}\n",
    "\n",
    "gases = [\n",
    "    'hydrogen', 'neon', 'argon', 'krypton', 'xenon',\n",
    "    'methane', 'ethane', 'ethene', 'acetylene',\n",
    "    'propane', 'propene',\n",
    "    'butane', 'isobutane',\n",
    "    '1-butene', 'cis-2-butene', 'trans-2-butene',\n",
    "    'isobutene',\n",
    "    'isopentane',\n",
    "    'carbon dioxide', 'sulphur dioxide', 'nitrogen dioxide',\n",
    "    'oxygen', 'carbon monoxide', 'nitrogen',\n",
    "    'benzene', 'toluene',\n",
    "    'water', 'methanol', 'ethanol', 'ammonia',\n",
    "]\n",
    "\n",
    "for mat in Counter([i.material for i in isotherms]).keys():\n",
    "    materials[mat] = {\n",
    "        gas: {\n",
    "            'iso': [],\n",
    "            'Kh': [],\n",
    "            'L': []\n",
    "        } for gas in gases}\n",
    "\n",
    "for iso in isotherms:\n",
    "    materials[iso.material][iso.adsorbate]['iso'].append(iso.filename)\n",
    "    materials[iso.material][iso.adsorbate]['Kh'].append(iso.henry_slope)\n",
    "    materials[iso.material][iso.adsorbate]['L'].append(iso.uptake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some outlier detection functions to be used later: gross outlier detection and interquartile outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kh_gross_outlier_rejection(a, l1=1e-7, l2=1e7):\n",
    "    return [i for i in a if l1 < i < l2 and not np.isnan(i)]\n",
    "\n",
    "\n",
    "def l_gross_outlier_rejection(a, l1=0, l2=1e7):\n",
    "    return [i for i in a if l1 <= i < l2 and not np.isnan(i)]\n",
    "\n",
    "\n",
    "def iqr_outlier_rejection(arr):\n",
    "    q75, q25 = np.nanpercentile(sorted(arr), [75, 25], interpolation='linear')\n",
    "    iqr = q75 - q25\n",
    "    l_b = q25 - (1.5 * iqr)\n",
    "    u_b = q75 + (1.5 * iqr)\n",
    "    return [a for a in arr if a > l_b and a < u_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier detection and median calculation for Henry constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat in materials:\n",
    "    for gas in gases:\n",
    "        K_hs = materials[mat][gas].get('Kh', None)\n",
    "        if K_hs is None:\n",
    "            materials[mat][gas]['mKh'] = np.nan\n",
    "            materials[mat][gas]['eKh'] = np.nan\n",
    "            materials[mat][gas]['lKh'] = np.nan\n",
    "\n",
    "        K_hs = kh_gross_outlier_rejection(K_hs)\n",
    "\n",
    "        if K_hs is None:\n",
    "            materials[mat][gas]['mKh'] = np.nan\n",
    "            materials[mat][gas]['eKh'] = np.nan\n",
    "            materials[mat][gas]['lKh'] = np.nan\n",
    "\n",
    "        nK_h = len(K_hs)\n",
    "        if nK_h == 0:\n",
    "            continue\n",
    "\n",
    "        if nK_h > 4:\n",
    "            K_hs = iqr_outlier_rejection(K_hs)\n",
    "            mK_h = np.median(K_hs)\n",
    "            eK_h = np.std(K_hs)\n",
    "        elif nK_h == 1:\n",
    "            mK_h = np.median(K_hs)\n",
    "            eK_h = 0\n",
    "        else:\n",
    "            mK_h = np.median(K_hs)\n",
    "            eK_h = np.std(K_hs)\n",
    "\n",
    "        materials[mat][gas]['mKh'] = mK_h\n",
    "        materials[mat][gas]['eKh'] = eK_h\n",
    "        materials[mat][gas]['lKh'] = nK_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier detection and median calculation for uptake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat in materials:\n",
    "    for gas in gases:\n",
    "\n",
    "        aL_s = materials[mat][gas].get('L', None)\n",
    "        if not aL_s:\n",
    "            materials[mat][gas]['mL'] = []\n",
    "            materials[mat][gas]['eL'] = []\n",
    "            materials[mat][gas]['lL'] = []\n",
    "            continue\n",
    "\n",
    "        pdL_s = pd.DataFrame(aL_s)\n",
    "\n",
    "        materials[mat][gas]['mL'] = [0]\n",
    "        materials[mat][gas]['eL'] = [0]\n",
    "        materials[mat][gas]['lL'] = [0]\n",
    "\n",
    "        for p in np.arange(0.5, 20.5, 0.5):\n",
    "            try:\n",
    "                L_s = l_gross_outlier_rejection(pdL_s[p])\n",
    "                if L_s is None:\n",
    "                    continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            nL_s = len(L_s)\n",
    "            if nL_s == 0:\n",
    "                materials[mat][gas]['mL'].append(np.nan)\n",
    "                materials[mat][gas]['eL'].append(np.nan)\n",
    "                materials[mat][gas]['lL'].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            if nL_s > 4:\n",
    "                L_s = iqr_outlier_rejection(L_s)\n",
    "                mL_s = np.median(L_s)\n",
    "                eL_s = np.std(L_s)\n",
    "            elif nL_s == 1:\n",
    "                mL_s = np.median(L_s)\n",
    "                eL_s = 0\n",
    "            else:\n",
    "                mL_s = np.median(L_s)\n",
    "                eL_s = np.std(L_s)\n",
    "\n",
    "            materials[mat][gas]['mL'].append(mL_s)\n",
    "            materials[mat][gas]['eL'].append(eL_s)\n",
    "            materials[mat][gas]['lL'].append(nL_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the resulting json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"./data/kpis.json\"\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(materials, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}