{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotherm processing\n",
    "\n",
    "This notebook will perform the following:\n",
    "\n",
    "- process previously selected isotherms to generate missing KPI\n",
    "- build and save a pandas DataFrame consisting of KPI and basic isotherm parameters\n",
    "- save trimmed down version of isotherms as an on-disc accessible dictionary (for dashboard access)\n",
    "- show examples of how the processing to remove outliers and obtain a single value and confidence range for material-adsorbate pairs\n",
    "\n",
    "To run this notebook the root directory must be the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pygaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: 'pressure_unit' was not specified, assumed as 'bar'\nWARNING: 'pressure_mode' was not specified, assumed as 'absolute'\nWARNING: 'adsorbent_unit' was not specified, assumed as 'g'\nWARNING: 'adsorbent_basis' was not specified, assumed as 'mass'\nWARNING: 'loading_unit' was not specified, assumed as 'mmol'\nWARNING: 'loading_basis' was not specified, assumed as 'molar'\nSelected20913isotherms\nLoaded 20913 isotherms.\n"
    }
   ],
   "source": [
    "# Database location\n",
    "db_path = pathlib.Path.cwd() / \"data\" / \"iso.db\"\n",
    "\n",
    "# Get all isotherms\n",
    "isotherms = pygaps.db_get_isotherms(db_path, {})\n",
    "\n",
    "print(f'Loaded {len(isotherms)} isotherms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute uptake values on pre-determined pressures. Do not extrapolate above maximum range. If any value below minimum range, use Henry constant to compute loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0%|          | 0/20913 [00:00<?, ?it/s]C:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n  app.launch_new_instance()\n100%|██████████| 20913/20913 [01:53<00:00, 183.56it/s]\n"
    }
   ],
   "source": [
    "no_loading_possible = []\n",
    "model_possible = []\n",
    "\n",
    "for iso in tqdm(isotherms):\n",
    "\n",
    "    iso.uptake = {}\n",
    "\n",
    "    prange = np.arange(0.5, 20.5, 0.5)\n",
    "    minp = min(iso.pressure(branch='ads'))\n",
    "    maxp = max(iso.pressure(branch='ads'))\n",
    "    model = [a for a in prange if a < minp]\n",
    "    direct = [a for a in prange if minp < a < maxp]\n",
    "\n",
    "    try:\n",
    "        for p in direct:\n",
    "            iso.uptake[p] = np.asscalar(iso.loading_at(p))\n",
    "    except Exception:\n",
    "        no_loading_possible.append(iso)\n",
    "        continue\n",
    "    # Take the data between 0 and x from the henry model\n",
    "    if model:\n",
    "        for p in model:\n",
    "            iso.uptake[p] = np.exp(iso.henry_k) * p\n",
    "        model_possible.append(iso)\n",
    "\n",
    "    iso.uptake[0] = 0.  # we automatically include 0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The calculated KPI are saved in a separate table in a HDF5 database. This will allow very fast retrieval when the dashboard is operated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 20913/20913 [00:00<00:00, 40234.00it/s]\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->axis0] [items->None]\n\n  f(store)\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->block0_items] [items->None]\n\n  f(store)\n"
    }
   ],
   "source": [
    "simple_dict = {}\n",
    "\n",
    "for iso in tqdm(isotherms):\n",
    "\n",
    "    addition = {\n",
    "        'mat' : iso.material,\n",
    "        'ads' : str(iso.adsorbate),\n",
    "        't' : iso.temperature,\n",
    "        'type' : iso.iso_type,\n",
    "        'kH' : np.log(iso.henry_k),\n",
    "    }\n",
    "    for p in np.arange(0.5, 20.5, 0.5):\n",
    "\n",
    "        addition[p] = iso.uptake.get(p, None)\n",
    "\n",
    "    simple_dict[iso.filename] = addition\n",
    "\n",
    "df = pd.DataFrame.from_dict(simple_dict, orient='index')\n",
    "df.to_hdf(pathlib.Path.cwd() / 'data' / 'kpi.h5', 'table', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For real isotherms to be displayed in the dashboard, some values are saved in an on-disk database. Here we use the python Shelve module for quick key-value pair storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 20913/20913 [03:25<00:00, 101.87it/s]\n"
    }
   ],
   "source": [
    "import shelve\n",
    "\n",
    "iso_packed = \"./data/iso-packed\"\n",
    "\n",
    "with shelve.open(iso_packed) as packed_dict:\n",
    "    for iso in tqdm(isotherms):\n",
    "        packed_dict[iso.filename] = {\n",
    "            'adsorbate': str(iso.adsorbate),\n",
    "            'material': iso.material,\n",
    "            'temp': iso.temperature,\n",
    "            'x': iso.pressure(),\n",
    "            'y': iso.loading(),\n",
    "            'doi': iso.DOI,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77bf9187004d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'data'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'kpi.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf(pathlib.Path.cwd() / 'data' / 'kpi.h5', 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->axis0] [items->None]\n\n  f(store)\nC:\\Users\\pauli\\Miniconda3\\envs\\dscience\\lib\\site-packages\\pandas\\io\\pytables.py:278: PerformanceWarning: \nyour performance may suffer as PyTables will pickle object types that it cannot\nmap directly to c-types [inferred_type->mixed,key->block0_items] [items->None]\n\n  f(store)\n"
    }
   ],
   "source": [
    "df.sample(n=500, random_state=1).to_hdf(pathlib.Path.cwd() / 'data' / 'kpi-smol.h5', 'table', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4413"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['mat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "554\n694\n"
    }
   ],
   "source": [
    "# select on experiment\n",
    "select = None\n",
    "if select:\n",
    "    dft = df[df['type']==select]\n",
    "else:\n",
    "    dft = df\n",
    "\n",
    "# select on temperature\n",
    "t_val = 303\n",
    "t_mar = 10\n",
    "dft = dft[dft['t'].between(t_val - t_mar, t_val + t_mar)]\n",
    "\n",
    "# create two clean dataframes with only material\n",
    "g1 = dft[dft['ads'] == 'nitrogen'].reset_index().drop(['index', 'type', 't', 'ads'], axis=1)\n",
    "g2 = dft[dft['ads'] == 'methane'].reset_index().drop(['index', 'type', 't', 'ads'], axis=1)\n",
    "\n",
    "# select only common materials\n",
    "common = list(set(g1['mat'].unique()).intersection(g2['mat'].unique()))\n",
    "g1 = g1[g1['mat'].isin(common)]\n",
    "g2 = g2[g2['mat'].isin(common)]\n",
    "\n",
    "print(len(g1))\n",
    "print(len(g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def _group_selection_context(groupby):\n",
    "    \"\"\"\n",
    "    Set / reset the _group_selection_context.\n",
    "    \"\"\"\n",
    "    groupby._set_group_selection()\n",
    "    yield groupby\n",
    "    groupby._reset_group_selection()\n",
    "\n",
    "def stats(series):\n",
    "\n",
    "    no_nan = series.dropna()\n",
    "    size = len(no_nan)\n",
    "\n",
    "    if size == 0:\n",
    "        med, std = np.nan, 0\n",
    "    elif size == 1:\n",
    "        med, std = float(no_nan), 0\n",
    "    elif 1 < size <= 4:\n",
    "        med, std = np.median(no_nan), np.std(no_nan)\n",
    "    elif 4 < size:\n",
    "        # Computing IQR\n",
    "        Q3, Q1 = np.nanpercentile(sorted(no_nan), [75, 25], interpolation='linear')\n",
    "        IQR = Q3 - Q1\n",
    "        o_rem = no_nan[(Q1 - 1.5 * IQR < no_nan) | (no_nan > Q3 + 1.5 * IQR)]\n",
    "        med, std = np.median(o_rem), np.std(o_rem)\n",
    "\n",
    "    return pd.Series((size, med, std),\n",
    "                     index=([\"size\", \"med\", \"err\"]),\n",
    "                     name=series.name)\n",
    "\n",
    "def calc_kpi(data):\n",
    "    with _group_selection_context(data):\n",
    "        return data.apply(\n",
    "            lambda x: pd.concat(\n",
    "                [stats(s) for _, s in x.items()],\n",
    "                axis=1, sort=False)\n",
    "        ).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(data, i_type, t_abs, t_tol, g1, g2):\n",
    "    if i_type:\n",
    "        dft = data[\n",
    "            (data['type'] == i_type) &\n",
    "            (data['t'].between(t_abs - t_tol, t_abs + t_tol))\n",
    "        ]\n",
    "    else:\n",
    "        dft = data[data['t'].between(t_abs - t_tol, t_abs + t_tol)]\n",
    "\n",
    "    g1_filt = dft[dft['ads'] == g1]\n",
    "    g2_filt = dft[dft['ads'] == g2]\n",
    "    common = list(set(g1_filt['mat'].unique()).intersection(g2_filt['mat'].unique()))\n",
    "    if len(common) == 0:\n",
    "        return None\n",
    "\n",
    "    return pd.merge(\n",
    "        calc_kpi(g1_filt[g1_filt['mat'].isin(common)].drop(\n",
    "            columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "        calc_kpi(g2_filt[g2_filt['mat'].isin(common)].drop(\n",
    "            columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "        on=('mat'), suffixes=('_x', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "--- 28.004876613616943 seconds ---\n"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "final = pd.merge(\n",
    "    proc(dft[dft['ads'] == 'nitrogen'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "    proc(dft[dft['ads'] == 'methane'].drop(columns=['type', 't', 'ads']).groupby('mat', sort=False)),\n",
    "    on=('mat'), suffixes=('_x', '_y'))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}