{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the NIST database\n",
    "\n",
    "This notebook has the following functionality:\n",
    " - A download of the NIST isotherm database in JSON form\n",
    " - Preliminary homogenisation of isotherm parameters\n",
    " - Pickling of this data to disk\n",
    "\n",
    "To run this notebook the root directory must be the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "basedir = pathlib.Path.cwd() / \"data\"\n",
    "isodb_base = \"https://adsorption.nist.gov/isodb/api/\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of isotherms\n",
    "\n",
    "We first download lists of all isotherms, materials and adsorbents in the NIST database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloaded 32552 isotherms.\n"
    }
   ],
   "source": [
    "iso_list = requests.get(isodb_base + \"isotherms.json\")\n",
    "with open(basedir / \"isotherm_list.json\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(iso_list.text)\n",
    "isotherms_parsed = iso_list.json()\n",
    "print(f\"Downloaded {len(isotherms_parsed)} isotherms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloaded 7008 materials.\n"
    }
   ],
   "source": [
    "mat_list = requests.get(isodb_base + \"materials.json\")\n",
    "with open(basedir / \"material_list.json\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(mat_list.text)\n",
    "materials_parsed = mat_list.json()\n",
    "print(f\"Downloaded {len(materials_parsed)} materials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloaded 356 probes.\n"
    }
   ],
   "source": [
    "ads_list = requests.get(isodb_base + \"gases.json\")\n",
    "with open(basedir / \"adsorbent_list.json\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(ads_list.text)\n",
    "adsorbents_parsed = ads_list.json()\n",
    "print(f\"Downloaded {len(adsorbents_parsed)} probes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In case these initial lists need to be reloaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loaded 32552 isotherms.\nLoaded 7008 materials.\nLoaded 356 materials.\n"
    }
   ],
   "source": [
    "with open(basedir / \"isotherm_list.json\", \"r\", encoding='utf-8') as f:\n",
    "    isotherms_parsed = json.load(f)\n",
    "print(f\"Loaded {len(isotherms_parsed)} isotherms.\")\n",
    "\n",
    "with open(basedir / \"material_list.json\", \"r\", encoding='utf-8') as f:\n",
    "    materials_parsed = json.load(f)\n",
    "print(f\"Loaded {len(materials_parsed)} materials.\")\n",
    "\n",
    "with open(basedir / \"adsorbent_list.json\", \"r\", encoding='utf-8') as f:\n",
    "    adsorbents_parsed = json.load(f)\n",
    "print(f\"Loaded {len(adsorbents_parsed)} adsorbents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concurrent download of ISODB\n",
    "\n",
    "The following cell uses a thread pool to download multiple isotherms in parralel from the list obtained previously. It is reasonably fast (a few minutes) but may encounter problems if the number of simultaneous connections is too high. Any errors are highlighted and saved in a separate list. This should be the first choice, but a sequential download can also be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Total number of iterations will be: 32552\n32552it [04:24, 123.25it/s]\n"
    }
   ],
   "source": [
    "isos = []\n",
    "errs = []\n",
    "CONNECTIONS = 50\n",
    "TIMEOUT = 10\n",
    "isodb_session = requests.Session()\n",
    "\n",
    "urls = [isodb_base + \"isotherm/\" + iso_raw['filename'] + '.json' for iso_raw in isotherms_parsed]\n",
    "\n",
    "def load_url(url, timeout):\n",
    "    ans = isodb_session.get(url, timeout=timeout)\n",
    "    return ans.json()\n",
    "\n",
    "print(f\"Total number of iterations will be: {len(isotherms_parsed)}\")\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=CONNECTIONS) as executor:\n",
    "    future_to_url = {executor.submit(load_url, url, TIMEOUT): url for url in urls}\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_url)):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            iso = future.result()\n",
    "        except Exception as exc:\n",
    "            print(exc)\n",
    "            errs.append(url)\n",
    "        else:\n",
    "            isos.append(iso)\n",
    "\n",
    "if errs:\n",
    "    print(\"Some errors occurred!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential download of ISODB\n",
    "\n",
    "If the concurrent code does not work, a sequential version is available. *Warning, this will take some time (can be several hours) depending on the ping and throughput, try concurrent version first.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 32552/32552 [2:07:34<00:00,  4.25it/s]\n"
    }
   ],
   "source": [
    "isos = []\n",
    "errs = []\n",
    "TIMEOUT = 5\n",
    "isodb_session = requests.Session()\n",
    "\n",
    "for iso_raw in tqdm(isotherms_parsed):\n",
    "    try:\n",
    "        iso = isodb_session.get(isodb_base + \"isotherm/\" + iso_raw['filename'] + '.json', timeout=TIMEOUT)\n",
    "        isos.append(iso.json())\n",
    "    except Exception as e:\n",
    "        errs.append(iso_raw)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This step is required due to several inconsistencies in the NIST ISODB. Due to the switch to a multicomponent JSON format, the *total_adsorption* field, which is supposed to show the total amount of all species adsorbed is sometimes left blank. Therefore, here we iterate and generate this field when it is absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 32552/32552 [00:02<00:00, 14112.17it/s]\nCorrections performed in 4839 isotherms.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fixes = 0\n",
    "\n",
    "for iso in tqdm(isos):\n",
    "    if iso['isotherm_data'][0]['total_adsorption'] is None:\n",
    "        fixes += 1\n",
    "        for point in iso['isotherm_data']:\n",
    "            point['total_adsorption'] = float(np.sum([dp['adsorption'] for dp in point['species_data']]))\n",
    "\n",
    "print(f\"Corrections performed in {fixes} isotherms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save (or load) pickled isotherms if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / \"isotherms.pickle\", 'wb') as f:\n",
    "    pickle.dump(isos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loaded 32552 full isotherms.\n"
    }
   ],
   "source": [
    "with open(basedir / \"isotherms.pickle\", 'rb') as f:\n",
    "    isos = pickle.load(f)\n",
    "print(f\"Loaded {len(isos)} full isotherms.\")"
   ]
  }
 ]
}